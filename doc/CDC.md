#* Change Data Capture *#

QuÃ© es "Change Data Capture"?

**Change Data Capture (CDC)** es una tÃ©cnica para detectar y capturar **cambios** (inserciones, actualizaciones, eliminaciones) en los datos de una base de datos, en tiempo real o casi real, para que puedas:

- Replicar esos cambios en otro sistema (por ejemplo, una base de datos secundaria o un data warehouse),
- Sincronizar microservicios que dependen de datos actualizados,
- Alimentar pipelines de datos, colas de eventos, etc.

---

### ğŸ§  Â¿CÃ³mo funciona en la prÃ¡ctica?

SupÃ³n que tienes esta tabla:

```sql
CREATE TABLE usuarios (
  id INT PRIMARY KEY,
  nombre TEXT,
  email TEXT
);
```

Y alguien hace:

```sql
UPDATE usuarios SET email = 'nuevo@email.com' WHERE id = 4;
```

CDC se encarga de **detectar ese cambio**, y luego **emitir un evento** o **registrarlo** en algÃºn lado, como:

```json
{
  "operation": "update",
  "table": "usuarios",
  "primary_key": 4,
  "before": { "email": "viejo@email.com" },
  "after": { "email": "nuevo@email.com" }
}
```

---

### ğŸ§° Â¿CÃ³mo se implementa?

Hay varias formas:

#### ğŸ”¹ 1. **Logs del sistema de base de datos**
- Se conecta directamente al **binlog** (MySQL), **WAL** (PostgreSQL), etc.
- Muy eficiente y no requiere tocar tu aplicaciÃ³n.
- Ej: [Debezium](https://debezium.io/) para Kafka, [Maxwell's Daemon](https://github.com/zendesk/maxwell)

#### ğŸ”¹ 2. **Triggers y tablas de auditorÃ­a**
- Agregas `TRIGGER`s que escriben los cambios en otra tabla.
- MÃ¡s manual, pero fÃ¡cil de entender y controlar.

#### ğŸ”¹ 3. **Consultas diferenciales**
- Comparas snapshots (por timestamp o versionado).
- Menos eficiente y no real-time.

---

### ğŸ“¦ Â¿CuÃ¡ndo usarlo?

- ReplicaciÃ³n de datos entre sistemas (por ejemplo, entre microservicios).
- Cargas incrementales en data warehouses (ETL/ELT).
- IntegraciÃ³n con sistemas de eventos o Kafka.
- AuditorÃ­a o trazabilidad.

---

### âš ï¸ Consideraciones

- Puede ser complejo de configurar en producciÃ³n.
- Debes tener cuidado con la **latencia**, **orden de los eventos**, y la **consistencia**.
- El volumen de datos puede crecer rÃ¡pido si no haces limpieza o compresiÃ³n de logs.

---

Â¿Quieres que te muestre un ejemplo simple con CDC en MySQL o PostgreSQL, o integrado con Kafka?


Ya, muÃ©strame un ejemplo de cada uno, MySQL y PostgreSQL, integrados con Kafka

Â¡Perfecto! Vamos a ver dos ejemplos reales de **Change Data Capture (CDC)** integrando:

1. **MySQL + Kafka**  
2. **PostgreSQL + Kafka**

Ambos usando **[Debezium](https://debezium.io/)**, que es una herramienta open source sÃºper popular para CDC sobre binlogs/WALs, y que se integra muy bien con Kafka.

---

## âœ… 1. MySQL + Kafka + Debezium

### ğŸ§© Componentes necesarios
- MySQL con binlog habilitado
- Kafka y Zookeeper
- Kafka Connect con plugin Debezium

### ğŸ”§ Paso a paso

#### ğŸ”¹ A. Configurar MySQL

En tu archivo `my.cnf` (Linux) o `my.ini` (Windows), habilita:

```ini
[mysqld]
server-id=223344
log_bin=mysql-bin
binlog_format=row
binlog_row_image=full
```

Reinicia MySQL y crea un usuario para CDC:

```sql
CREATE USER 'debezium'@'%' IDENTIFIED BY 'dbz';
GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'debezium'@'%';
```

#### ğŸ”¹ B. Crear conector en Kafka Connect

EnvÃ­a este JSON a Kafka Connect (por ejemplo, con `curl` a `localhost:8083/connectors`):

```json
{
  "name": "mysql-usuarios-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "localhost",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.server.id": "184054",
    "database.server.name": "mysql-usuarios",
    "database.include.list": "mi_basedatos",
    "table.include.list": "mi_basedatos.usuarios",
    "include.schema.changes": "false"
  }
}
```

#### ğŸ”¹ C. Resultado

- Cada vez que cambias `usuarios`, Debezium publicarÃ¡ mensajes en:
  
  ```
  mysql-usuarios.mi_basedatos.usuarios
  ```

- El payload serÃ¡ como:

```json
{
  "before": {
    "id": 4,
    "nombre": "Juan"
  },
  "after": {
    "id": 4,
    "nombre": "Pedro"
  },
  "op": "u", // update
  "ts_ms": 1712345678901
}
```

---

## âœ… 2. PostgreSQL + Kafka + Debezium

### ğŸ§© Requisitos
- PostgreSQL con WAL habilitado
- Plugin `wal2json` (o `pgoutput`)
- Kafka + Debezium + Kafka Connect

### ğŸ”§ Paso a paso

#### ğŸ”¹ A. Configurar PostgreSQL

En `postgresql.conf`:

```conf
wal_level = logical
max_replication_slots = 4
max_wal_senders = 4
```

Y en `pg_hba.conf`:

```
host replication debezium 0.0.0.0/0 md5
```

Crea usuario para CDC:

```sql
CREATE USER debezium WITH REPLICATION PASSWORD 'dbz';
```

#### ğŸ”¹ B. Crear conector

```json
{
  "name": "pg-usuarios-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.dbname": "mi_basedatos",
    "database.server.name": "pg-usuarios",
    "table.include.list": "public.usuarios",
    "plugin.name": "pgoutput"
  }
}
```

#### ğŸ”¹ C. Resultado

Debezium empezarÃ¡ a emitir eventos en el tÃ³pico:

```
pg-usuarios.public.usuarios
```

Con eventos en el mismo formato Debezium (con `before`, `after`, `op`, etc.).

---

## ğŸ¥ Â¿Y luego quÃ©?

Desde esos tÃ³picos puedes:

- Leer los eventos con un consumidor de Kafka en Rust, Python, Node, etc.
- Enviar los datos a una base de datos secundaria o a un sistema de bÃºsqueda.
- Transformarlos con Kafka Streams o KSQL.

---

Â¿Quieres que te arme un docker-compose mÃ­nimo con MySQL/PostgreSQL + Kafka + Debezium para probar todo esto localmente?
